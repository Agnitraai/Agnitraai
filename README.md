# agnitraai

Agnitra is an end-to-end optimization platform that wraps model tuning, telemetry, and metered billing into a single developer flow. The SDK and CLI make `agnitra.optimize(model)` feel instantaneous while the control plane meters GPU hours for a usage-based SaaS model.

## Highlights
- Unified CLI (`agnitra`) and Python SDK for profiling, tuning, and exporting optimized TorchScript artifacts.
- Runtime agent that can inject Triton kernels or forward hooks on the fly.
- Telemetry collectors, LLM-guided kernel suggestions, and RL-backed refinements.
- Usage metering architecture that links telemetry → usage logs → Stripe metered billing.

## Installation

### From Wheel (recommended)

```
pip install agnitra
```

Rebuild the wheel from source when iterating locally:

```
python -m build --wheel
python -m pip install --force-reinstall --no-index --find-links dist agnitra
```

### From Source

```
pip install -e .[openai,rl]
```

Optional extras:
- `agnitra[openai]` → OpenAI Responses API client.
- `agnitra[rl]` → PPO tuning via Stable Baselines3 + Gymnasium.
- `agnitra[nvml]` → GPU telemetry using NVML.

## Quick Start

### 1. Watch the walkthrough

- `launch_demo.mp4` – short narrated slides covering the milestone demo.

### 2. Run the milestone script

```
python demo.py --sample-shape 1,16,64
```

The script performs three sequential demos:

| Segment | What it shows |
| --- | --- |
| **Baseline vs Optimized** | Uses `agnitra.optimize_model` with the TinyLlama fixture and reports latency uplift. |
| **CLI Optimization** | Executes `agnitra optimize --model tinyllama.pt` and saves an optimized TorchScript artifact. |
| **Kernel Injection** | Generates a Triton kernel and swaps an FX node via `RuntimePatcher`. |

### 3. CLI cheatsheet

```
agnitra --help
agnitra optimize --model tinyllama.pt --input-shape 1,16,64
```

### 4. SDK in your code

```python
import torch
from agnitra import optimize_model

model = torch.jit.load("tinyllama.pt")
sample = torch.randn(1, 16, 64)
optimized = optimize_model(model, input_tensor=sample, enable_rl=False)
```

## Usage-Based SaaS Architecture

The repository tracks the implementation plan for a pay-per-optimization product. Key building blocks:

- **Runtime Agent** – intercepts CUDA/ROCm/Triton workloads, applies passes (KernelAutoTuner, TensorLayoutOptimizer, MemoryPrefetcher, GraphFuser) and records tokens/sec, latency, GPU utilisation before/after optimization.
- **Telemetry + Metering** – usage events flow through `agnitra.sdk.telemetry` (buffer + signer), land in the control plane via `/usage/ingest`, and roll up into GPU-hour and performance-uplift metrics per project.
- **Control Plane** – FastAPI (REST) + gRPC fronting an `Optimize()` endpoint. Async workers aggregate usage, enrich with cost data, and call Stripe Metered Billing. Webhooks reconcile invoices with project owners.
- **Billing Loop** – Stripe metered usage records keyed by project ID + region + tag. Usage snapshots are bundled into invoices. Saved reports highlight cost savings vs baseline compute spend.
- **Developer Surface** – function wrapper (`agnitra.optimize`), context manager (`optimize_ctx`), and decorator (`agnitra_step`) so optimisation happens automatically.

### Repository Layout (Monorepo blueprint)

```
agnitra/
├─ sdk/python/
│  ├─ agnitra/
│  │  ├─ optimize.py        # optimize(), optimize_ctx, agnitra_step
│  │  ├─ passes/            # pluggable optimization passes
│  │  ├─ backends/          # torch/tf/jax adapters
│  │  ├─ telemetry.py       # usage events buffer + signer
│  │  ├─ auth.py            # session token management
│  │  ├─ config.py          # Config dataclass
│  │  └─ cli.py             # Click CLI wiring
│  └─ pyproject.toml
├─ control-plane/
│  ├─ api/                  # REST/gRPC services
│  ├─ metering/             # aggregation, rating, invoicing
│  ├─ billing/              # Stripe/Paddle adapters + webhooks
│  └─ db/                   # migrations for usage tables
└─ infra/                   # Docker, Helm, Terraform manifests
```

### Metering Flow

1. SDK attaches to a model – emits a `usage.attach` event with tags (`model`, `env`, `region`).
2. Runtime agent records baseline + optimized telemetry (latency, tokens/sec, GPU utilisation).
3. Control plane ingests events, aggregates GPU hours optimised, and calculates uplift.
4. Stripe metered billing rates GPU hours / tokens and issues invoices.
5. Dashboard (future) visualises savings and lets teams approve optimisations before rollout.

## Profiling & Visualisation

The classic profiling flow remains available:

1. Profile a model: `python -m agnitra.cli profile tinyllama.pt --input-shape 1,16,64 --output telemetry.json`
2. Load telemetry + extract an FX graph IR via `agnitra.core.ir.graph_extractor`.
3. Explore results inside `agnitra_enhanced_demo.ipynb` (Colab badge included).

## Development

```
pytest -q
```

Artifacts generated by tests (profiles, telemetry) live under `benchmarks/` and `agnitraai/context/`; consult `.gitignore` for the latest ignore rules. Update docs when the CLI or SDK experience changes.

## Resources
- `docs/responses_api.md` – OpenAI Responses API spec followed by the SDK.
- `docs/non_interactive_codex_usage.txt` – headless Codex automation notes.
- `docs/ui_ux_handoff.md` – UX flows and SaaS onboarding notes.
- `AGENTS.md` + `notes.yaml` – roadmap fragments and agent experiments.
