{
  "model": "tinyllama.pt",
  "device": "NVIDIA A100-SXM4-40GB",
  "meta": {
    "python_version": "3.12.11",
    "torch_version": "2.8.0+cu126",
    "cuda_available": true,
    "cuda_version": "12.6",
    "cudnn_version": 91002,
    "device_name": "NVIDIA A100-SXM4-40GB",
    "device_capability": [
      8,
      0
    ],
    "model_num_parameters": 164544
  },
  "gpu": {
    "gpu_utilisation": 0,
    "memory_utilisation": 0,
    "power_watts": 50.55,
    "temperature_c": 34.0,
    "fan_speed_pct": null,
    "name": "NVIDIA A100-SXM4-40GB",
    "driver_version": "550.54.15",
    "vram_total_mb": 40960.0,
    "vram_used_mb": 1537.75,
    "vram_free_mb": 39422.25,
    "cuda_allocated_mb": 8.9365234375,
    "cuda_reserved_mb": 22.0
  },
  "behavior": {
    "op_count_total": 39,
    "unique_ops": 39,
    "matmul_ops": 2,
    "conv_ops": 0,
    "activation_ops": 2,
    "norm_ops": 2,
    "inplace_ops": 1,
    "kernel_launches": 36,
    "top_cuda_ms": [
      {
        "name": "[memory]",
        "cuda_ms": 0.0
      },
      {
        "name": "forward",
        "cuda_ms": 0.0
      },
      {
        "name": "aten::slice",
        "cuda_ms": 0.0
      },
      {
        "name": "aten::as_strided",
        "cuda_ms": 0.0
      },
      {
        "name": "aten::add",
        "cuda_ms": 0.0
      },
      {
        "name": "Unrecognized",
        "cuda_ms": 0.0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_ms": 0.0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_ms": 0.0
      },
      {
        "name": "aten::transpose",
        "cuda_ms": 0.0
      },
      {
        "name": "aten::linear",
        "cuda_ms": 0.0
      }
    ],
    "top_cuda_mem_bytes": [
      {
        "name": "[memory]",
        "bytes": 0
      },
      {
        "name": "forward",
        "bytes": 0
      },
      {
        "name": "aten::slice",
        "bytes": 0
      },
      {
        "name": "aten::as_strided",
        "bytes": 0
      },
      {
        "name": "aten::add",
        "bytes": 0
      },
      {
        "name": "Unrecognized",
        "bytes": 0
      },
      {
        "name": "cudaLaunchKernel",
        "bytes": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "bytes": 0
      },
      {
        "name": "aten::transpose",
        "bytes": 0
      },
      {
        "name": "aten::linear",
        "bytes": 0
      }
    ],
    "activation_bytes_total": 8192,
    "top_activation_layers": [
      {
        "name": "",
        "bytes": 8192
      }
    ],
    "gpu_util_mean": 1.0526315789473684,
    "gpu_util_max": 6,
    "mem_util_max": 0
  },
  "opportunities": {
    "fp16_bf16_candidates": [],
    "prune_candidates": []
  },
  "summary": {
    "num_events": 39,
    "total_cuda_time_ms": 0.0,
    "total_cpu_time_ms": 0.014760910000000006,
    "top_by_time": [
      {
        "name": "[memory]",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 46,
        "cuda_mem": 0,
        "cpu_mem": -32
      },
      {
        "name": "forward",
        "cuda_ms": 0.0,
        "cpu_ms": 0.005056336,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_ms": 0.0,
        "cpu_ms": 8.057799999999924e-05,
        "count": 9,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_ms": 0.0,
        "cpu_ms": 6.568799999999778e-05,
        "count": 69,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_ms": 0.0,
        "cpu_ms": 0.002538143000000001,
        "count": 9,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_ms": 0.0,
        "cpu_ms": 0.002171375,
        "count": 1,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00036602299999999966,
        "count": 36,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 9,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0001611260000000043,
        "count": 42,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0007963810000000012,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_ms": 0.0,
        "cpu_ms": 3.954700000000048e-05,
        "count": 9,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00014031900000000225,
        "count": 57,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_ms": 0.0,
        "cpu_ms": 8.748099999999931e-05,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0005460909999999999,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ],
    "top_by_mem": [
      {
        "name": "[memory]",
        "cuda_mem": 0,
        "cpu_mem": -32
      },
      {
        "name": "forward",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ]
  },
  "model_profile": {
    "layers": [
      {
        "name": "",
        "type": "_Wrapper",
        "class_path": "cli.profile._Wrapper",
        "parameters": [],
        "buffers": [],
        "attributes": {},
        "input_shapes": [
          [
            1,
            16,
            64
          ]
        ],
        "output_shapes": [
          [
            1,
            16,
            64
          ]
        ],
        "output_dtype": "float32",
        "cuda_mem_alloc_delta_bytes": 55808,
        "forward_time_ms": 3.118800999800442
      },
      {
        "name": "inner",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.embed",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [
          {
            "name": "weight",
            "shape": [
              2048,
              64
            ],
            "numel": 131072,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "weight"
          }
        ],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.pos",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [],
        "buffers": [
          {
            "name": "pe",
            "shape": [
              1,
              512,
              64
            ],
            "numel": 32768,
            "dtype": "float32",
            "device": "cuda:0",
            "kind": "buffer"
          }
        ],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.attn",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [
          {
            "name": "in_proj_weight",
            "shape": [
              192,
              64
            ],
            "numel": 12288,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "parameter"
          },
          {
            "name": "in_proj_bias",
            "shape": [
              192
            ],
            "numel": 192,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "parameter"
          }
        ],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.attn.out_proj",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [
          {
            "name": "weight",
            "shape": [
              64,
              64
            ],
            "numel": 4096,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "weight"
          },
          {
            "name": "bias",
            "shape": [
              64
            ],
            "numel": 64,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "bias"
          }
        ],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.norm1",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [
          {
            "name": "weight",
            "shape": [
              64
            ],
            "numel": 64,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "weight"
          },
          {
            "name": "bias",
            "shape": [
              64
            ],
            "numel": 64,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "bias"
          }
        ],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.mlp",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.mlp.0",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [
          {
            "name": "weight",
            "shape": [
              128,
              64
            ],
            "numel": 8192,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "weight"
          },
          {
            "name": "bias",
            "shape": [
              128
            ],
            "numel": 128,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "bias"
          }
        ],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.mlp.1",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.mlp.2",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [
          {
            "name": "weight",
            "shape": [
              64,
              128
            ],
            "numel": 8192,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "weight"
          },
          {
            "name": "bias",
            "shape": [
              64
            ],
            "numel": 64,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "bias"
          }
        ],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      },
      {
        "name": "inner.norm2",
        "type": "RecursiveScriptModule",
        "class_path": "torch.jit._script.RecursiveScriptModule",
        "parameters": [
          {
            "name": "weight",
            "shape": [
              64
            ],
            "numel": 64,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "weight"
          },
          {
            "name": "bias",
            "shape": [
              64
            ],
            "numel": 64,
            "dtype": "float32",
            "device": "cuda:0",
            "requires_grad": true,
            "kind": "bias"
          }
        ],
        "buffers": [],
        "attributes": {},
        "input_shapes": [],
        "output_shapes": [],
        "output_dtype": null,
        "cuda_mem_alloc_delta_bytes": null,
        "forward_time_ms": null
      }
    ],
    "parameter_count_total": 164544,
    "parameter_count_trainable": 164544,
    "parameter_count_frozen": 0,
    "parameter_dtypes": {
      "float32": 164544
    },
    "buffer_dtypes": {
      "float32": 32768
    },
    "model_dtype": "float32"
  },
  "training_summary": {
    "num_events": 120,
    "total_cuda_time_ms": 0.0,
    "total_cpu_time_ms": 0.508841494,
    "top_by_time": [
      {
        "name": "Optimizer.zero_grad#SGD.zero_grad",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00020852600000001177,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "forward",
        "cuda_ms": 0.0,
        "cpu_ms": 0.005142701000000009,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_ms": 0.0,
        "cpu_ms": 8.605400000001111e-05,
        "count": 9,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00016986300000000382,
        "count": 162,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00260038000000001,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0022044559999999996,
        "count": 1,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0788893019999999,
        "count": 135,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 18,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0004440889999998967,
        "count": 111,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0008378630000000162,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0005144550000000194,
        "count": 57,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_ms": 0.0,
        "cpu_ms": 0.000252965000000077,
        "count": 105,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0002951269999999868,
        "count": 39,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0005693650000000161,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ],
    "top_by_mem": [
      {
        "name": "Optimizer.zero_grad#SGD.zero_grad",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "forward",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ]
  },
  "validation_summary": {
    "num_events": 32,
    "total_cuda_time_ms": 0.0,
    "total_cpu_time_ms": 0.016118844,
    "top_by_time": [
      {
        "name": "forward",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0061136459999999995,
        "count": 2,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_ms": 0.0,
        "cpu_ms": 7.6071e-05,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_ms": 0.0,
        "cpu_ms": 3.947800000000339e-05,
        "count": 42,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0030219260000000003,
        "count": 6,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0021910020000000005,
        "count": 1,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0008276229999999978,
        "count": 22,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 6,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::_native_multi_head_attention",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0008000340000000006,
        "count": 2,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_ms": 0.0,
        "cpu_ms": 4.899999999999773e-05,
        "count": 38,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_ms": 0.0,
        "cpu_ms": 8.67269999999994e-05,
        "count": 30,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0005280379999999991,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_ms": 0.0,
        "cpu_ms": 3.5998999999999795e-05,
        "count": 10,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_ms": 0.0,
        "cpu_ms": 4.157299999999987e-05,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0003667339999999999,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ],
    "top_by_mem": [
      {
        "name": "forward",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::_native_multi_head_attention",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ]
  }
}