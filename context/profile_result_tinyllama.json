{
  "model": "tinyllama.pt",
  "device": "NVIDIA A100-SXM4-40GB",
  "meta": {
    "python_version": "3.12.11",
    "torch_version": "2.8.0+cu126",
    "cuda_available": true,
    "cuda_version": "12.6",
    "cudnn_version": 91002,
    "device_name": "NVIDIA A100-SXM4-40GB",
    "device_capability": [
      8,
      0
    ],
    "model_num_parameters": 164544
  },
  "gpu": {
    "gpu_utilisation": 0,
    "memory_utilisation": 0,
    "power_watts": 50.602,
    "temperature_c": 34.0,
    "fan_speed_pct": null,
    "name": "NVIDIA A100-SXM4-40GB",
    "driver_version": "550.54.15",
    "vram_total_mb": 40960.0,
    "vram_used_mb": 1537.75,
    "vram_free_mb": 39422.25,
    "cuda_allocated_mb": 8.88330078125,
    "cuda_reserved_mb": 22.0
  },
  "summary": {
    "num_events": 46,
    "total_cuda_time_ms": 0.0,
    "total_cpu_time_ms": 0.45996630600000005,
    "top_by_time": [
      {
        "name": "defaults",
        "cuda_ms": 0.0,
        "cpu_ms": 8.004999999997381e-06,
        "count": 6,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "forward",
        "cuda_ms": 0.0,
        "cpu_ms": 0.124649421,
        "count": 1,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_ms": 0.0,
        "cpu_ms": 6.633899999999267e-05,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_ms": 0.0,
        "cpu_ms": 6.783800000000337e-05,
        "count": 23,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_ms": 0.0,
        "cpu_ms": 0.015374145000000018,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_ms": 0.0,
        "cpu_ms": 0.002144853999999992,
        "count": 1,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_ms": 0.0,
        "cpu_ms": 0.03443791900000001,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Runtime Triggered Module Loading",
        "cuda_ms": 0.0,
        "cpu_ms": 0.03735216300000003,
        "count": 14,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Lazy Function Loading",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00027772000000003027,
        "count": 6,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00012748199999995996,
        "count": 14,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_ms": 0.0,
        "cpu_ms": 0.086371231,
        "count": 4,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_ms": 0.0,
        "cpu_ms": 3.99040000000241e-05,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00012849799999996322,
        "count": 19,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_ms": 0.0,
        "cpu_ms": 6.842300000000978e-05,
        "count": 4,
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ],
    "top_by_mem": [
      {
        "name": "defaults",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "forward",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Runtime Triggered Module Loading",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Lazy Function Loading",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ]
  },
  "training_summary": {
    "num_events": 120,
    "total_cuda_time_ms": 0.0,
    "total_cpu_time_ms": 0.5117742310000001,
    "top_by_time": [
      {
        "name": "Optimizer.zero_grad#SGD.zero_grad",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00023097299999999535,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "forward",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0074475269999999885,
        "count": 3,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_ms": 0.0,
        "cpu_ms": 8.268499999997562e-05,
        "count": 9,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00017032999999992468,
        "count": 162,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0025374580000000267,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_ms": 0.0,
        "cpu_ms": 0.002138,
        "count": 1,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_ms": 0.0,
        "cpu_ms": 0.07915097099999995,
        "count": 135,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 18,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00046879099999999423,
        "count": 111,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_ms": 0.0,
        "cpu_ms": 0.000867605999999993,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00047431800000005204,
        "count": 57,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0002668240000001065,
        "count": 105,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0002939610000000416,
        "count": 39,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0005705969999999825,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ],
    "top_by_mem": [
      {
        "name": "Optimizer.zero_grad#SGD.zero_grad",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "forward",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ]
  },
  "validation_summary": {
    "num_events": 32,
    "total_cuda_time_ms": 0.0,
    "total_cpu_time_ms": 0.013599492999999999,
    "top_by_time": [
      {
        "name": "forward",
        "cuda_ms": 0.0,
        "cpu_ms": 0.005260911,
        "count": 2,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_ms": 0.0,
        "cpu_ms": 6.476499999999945e-05,
        "count": 12,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_ms": 0.0,
        "cpu_ms": 3.4505999999999375e-05,
        "count": 42,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0023746400000000003,
        "count": 6,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0021511929999999996,
        "count": 1,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_ms": 0.0,
        "cpu_ms": 0.00022787199999999849,
        "count": 22,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 6,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::_native_multi_head_attention",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0006875309999999999,
        "count": 2,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_ms": 0.0,
        "cpu_ms": 4.447399999999834e-05,
        "count": 38,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_ms": 0.0,
        "cpu_ms": 7.84680000000003e-05,
        "count": 30,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0004735260000000003,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_ms": 0.0,
        "cpu_ms": 4.4393999999999325e-05,
        "count": 10,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_ms": 0.0,
        "cpu_ms": 3.763400000000047e-05,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0003268700000000008,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_ms": 0.0,
        "cpu_ms": 0.0,
        "count": 8,
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ],
    "top_by_mem": [
      {
        "name": "forward",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::slice",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::as_strided",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::add",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "Unrecognized",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "cudaLaunchKernel",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul> >(int, at::native::CUDAFunctor_add<float>, std::array<char*, 3ul>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::_native_multi_head_attention",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::view",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::transpose",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::linear",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::reshape",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::t",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "aten::addmm",
        "cuda_mem": 0,
        "cpu_mem": 0
      },
      {
        "name": "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",
        "cuda_mem": 0,
        "cpu_mem": 0
      }
    ]
  }
}