---
title: "Architecture Overview"
description: "Understand how the Agnitra optimization stack links telemetry, AI planning, kernel generation, and billing."
---

# Architecture Overview

Agnitra orchestrates a telemetry-driven optimization loop so teams can ship faster models without rewriting kernels by hand. The MVP scope combines collectors, AI planning, runtime patching, and billing into a single pipeline. This page distills the product requirement document into concrete components you can extend.

## High-Level Flow

1. **Telemetry collector** instruments TorchScript execution with `torch.profiler` and optional NVML hooks. It emits latency, tokens/sec, memory, and GPU hours saved as JSON snapshots.
2. **Graph extractor** traces the workload with `torch.fx`, aligning profiler events to graph nodes so the optimizer knows which kernels to target.
3. **AI optimizer** blends OpenAI Responses API hints with reinforcement learning (PPO) refinements to propose tuned kernel parameters.
4. **Kernel generator** assembles Triton or CUDA templates using the selected parameters and validates functional equivalence against baseline outputs.
5. **Runtime patcher** swaps optimized kernels into the live graph, preserving module APIs while recording telemetry deltas for auditing.
6. **Usage metering** converts before/after telemetry into billable usage events that flow to Stripe, AWS Marketplace, or internal ledgers.

The CLI and Python SDK orchestrate each stage and persist artifacts so teams can trace every optimization decision.

## Core Modules

| Module | Location | Responsibilities |
| --- | --- | --- |
| Telemetry Collector | `agnitra/telemetry_collector.py`, `agnitra/core/telemetry/` | Capture profiler data, correlate with NVML metrics, serialize telemetry bundles. |
| IR Graph Extractor | `agnitra/core/graph/` | Build FX graphs with node-level telemetry annotations. |
| AI Optimizer | `agnitra/core/optimizer/` | Call the Responses API, run PPO fine-tuning loops, and aggregate kernel suggestions. |
| Kernel Generator | `agnitra/core/kernel/` | Render Triton/CUDA templates, validate outputs, and score expected speedups. |
| Runtime Patcher | `agnitra/core/runtime/` | Inject optimized kernels, manage fallbacks, and surface telemetry deltas. |
| Usage Meter | `agnitra/core/metering/usage_meter.py` | Compute GPU hours saved, totals, and marketplace payloads. |
| CLI & SDK | `cli/`, `agnitra/sdk.py`, `agnitra/cli.py` | Provide developer entry points, lazy-load heavy deps, guarantee exit codes. |
| Benchmarking | `agnitra/benchmarks/`, `benchmark_runner.py` | Compare baseline vs optimized latency, throughput, and cost. |

## Control Plane & Surface Area

- **CLI (`agnitra`)** — Subcommands for profiling, benchmarking, and optimization with reusable flags across on-prem and hosted workflows.
- **Agentic Optimization API (`agnitra-api`)** — Starlette/FastAPI service that accepts graph + telemetry artifacts, queues optimization jobs, and exposes `/usage` for billing.
- **Dashboard (`agnitra-dashboard`)** — Lightweight telemetry viewer that highlights speedups, GPU savings, and license compliance.
- **JavaScript SDK (`js/`)** — Bridges control-plane APIs into browser or Node environments with typed helpers and async queues.

## Deployment & Operations

- Minimum Python 3.8 and PyTorch 2.0 with CUDA/cuDNN when targeting GPUs.
- Optional extras enable NVML telemetry, marketplace adapters, and RL toolchains (`pip install agnitra[nvml,marketplace,rl]`).
- Production deployments rotate API keys every 90 days, enforce request signing, and log optimization metadata to your SIEM for traceability.

## Success Metrics (MVP Targets)

| Metric | Goal |
| --- | --- |
| Tokens per second uplift | ≥ 20% |
| Latency reduction | ≥ 15% |
| Memory efficiency | ≥ 25% |
| Integration time | < 10 minutes |
| Output correctness | ≥ 99.9% parity with baseline |

## Roadmap Highlights

Post-MVP, Agnitra expands with telemetry dashboards, broader hardware coverage (ROCm, Tenstorrent), and automated agent fine-tuning from production inference logs. See the PRD for the full roadmap and personas that guide prioritization.
