"""Autogenerated Triton kernel for vector addition."""

from __future__ import annotations

import torch

try:
    import triton
    import triton.language as tl
except ImportError:  # pragma: no cover - optional dependency
    triton = None
    tl = None


BLOCK_SIZE = 256


def _ceil_div(x: int, y: int) -> int:
    return (x + y - 1) // y


if triton is not None:

    @triton.jit
    def vector_add_kernel(x_ptr, y_ptr, output_ptr, n_elements, *, BLOCK_SIZE: tl.constexpr):
        pid = tl.program_id(axis=0)
        start = pid * BLOCK_SIZE
        offsets = start + tl.arange(0, BLOCK_SIZE)
        mask = offsets < n_elements
        x = tl.load(x_ptr + offsets, mask=mask, other=0.0)
        y = tl.load(y_ptr + offsets, mask=mask, other=0.0)
        tl.store(output_ptr + offsets, x + y, mask=mask)


def run_kernel(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
    """Compute ``x + y`` via Triton when available else Torch fallback."""

    if x.shape != y.shape:
        raise ValueError("Inputs must share the same shape")
    if x.dim() != 1:
        raise ValueError("Only 1D tensors are supported")
    x = x.to(dtype=torch.float32)
    y = y.to(dtype=torch.float32)

    if triton is None:
        return x + y

    n_elements = x.numel()
    output = torch.empty_like(x)
    grid = (_ceil_div(n_elements, BLOCK_SIZE),)
    vector_add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=BLOCK_SIZE)
    return output