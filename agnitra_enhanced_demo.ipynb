{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775328a",
   "metadata": {
    "tags": [
     "colab-setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Base setup: Colab secrets, repo clone, env vars\n",
    "import os, pathlib\n",
    "try:\n",
    "    from google.colab import userdata  # type: ignore\n",
    "    GH_TOKEN = userdata.get('GH_TOKEN')\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "    AGNITRAAI_REPO = userdata.get('AGNITRAAI_REPO')\n",
    "    if OPENAI_API_KEY: os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "    if GOOGLE_API_KEY: os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
    "    repo_path = pathlib.Path('/content/agnitraai')\n",
    "    if pathlib.Path('/content').exists() and not repo_path.exists() and GH_TOKEN and AGNITRAAI_REPO:\n",
    "        repo_url = f'https://{GH_TOKEN}@{AGNITRAAI_REPO}'\n",
    "        get_ipython().system(f'git clone {repo_url} {repo_path}')\n",
    "        os.chdir(repo_path)\n",
    "    elif repo_path.exists():\n",
    "        os.chdir(repo_path)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee7f54",
   "metadata": {
    "tags": [
     "install-cli"
    ]
   },
   "outputs": [],
   "source": [
    "# Install Agnitra locally so `agnitra` CLI is available in Colab\n",
    "import pathlib, os\n",
    "repo_path = pathlib.Path('/content/agnitraai')\n",
    "if repo_path.exists():\n",
    "    get_ipython().system('python -m pip install -q -e /content/agnitraai')\n",
    "else:\n",
    "    get_ipython().system('python -m pip install -q -e .')\n",
    "# Quick sanity: show help (fallback to module if console script not found)\n",
    "_ = get_ipython().system('agnitra --help >/dev/null 2>&1 || python -m agnitraai.cli.main --help >/dev/null 2>&1')\n",
    "print('Agnitra CLI available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7eaf32",
   "metadata": {},
   "source": [
    "# Agnitra CLI Demo — TinyLlama\n",
    "\n",
    "This notebook demonstrates a clean, CLI-first workflow:\n",
    "- Prepare a tiny TinyLlama-like model\n",
    "- Run profiling via `agnitra profile ...` (CPU/GPU auto-detected)\n",
    "- Load telemetry artifacts and visualize key results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal environment check and CLI availability\n",
    "import shutil, subprocess, sys, json\n",
    "try:\n",
    "    import torch\n",
    "    print(f'[Env] CUDA available: {torch.cuda.is_available()}')\n",
    "    if torch.cuda.is_available():\n",
    "        print('[Env] GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print('[Env] CPU-only runtime')\n",
    "except Exception as e:\n",
    "    print('[Env] Torch check skipped:', e)\n",
    "\n",
    "if shutil.which('agnitra') is None:\n",
    "    print('[Setup] Installing local CLI ...')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', '-e', 'agnitraai'])\n",
    "else:\n",
    "    print('[Setup] agnitra CLI found')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d72f7",
   "metadata": {},
   "source": [
    "## Prepare tiny model\n",
    "Generates `tinyllama.pt` (TorchScript) and a small info JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "cmd = [sys.executable, 'prepare_tinyllama.py']\n",
    "print('$', ' '.join(cmd))\n",
    "subprocess.check_call(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b1e7d",
   "metadata": {},
   "source": [
    "## Profile using the Agnitra CLI\n",
    "Runs the CLI and prints only the CLI's stdout for a clean view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shlex, subprocess, shutil, sys\n",
    "env = os.environ.copy()\n",
    "env['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "env['GYM_DISABLE_WARNINGS'] = '1'\n",
    "base_cmd = 'agnitra profile tinyllama.pt --input-shape 1,16,64 --output telemetry.json'\n",
    "if shutil.which('agnitra') is None:\n",
    "    base_cmd = f'{sys.executable} -m cli.main profile tinyllama.pt --input-shape 1,16,64 --output telemetry.json'\n",
    "print('$', base_cmd)\n",
    "res = subprocess.run(shlex.split(base_cmd), env=env, check=True, capture_output=True, text=True)\n",
    "print(res.stdout)  # keep CLI output clean (stderr suppressed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb01e1c",
   "metadata": {},
   "source": [
    "## Load telemetry and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03793baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "root = Path('agnitraai')/ 'context'\n",
    "telemetry = json.loads(Path('telemetry.json').read_text())\n",
    "train = json.loads(Path('telemetry_train.json').read_text()) if Path('telemetry_train.json').exists() else {'events': []}\n",
    "summary = json.loads((root / 'profile_result_tinyllama.json').read_text())\n",
    "\n",
    "def to_ms_ns(v):\n",
    "    try: return float(v)/1e6\n",
    "    except: return 0.0\n",
    "\n",
    "total_cpu_ms = sum(to_ms_ns(e.get('cpu_time_total',0.0)) for e in telemetry.get('events', []))\n",
    "total_cuda_ms = sum(to_ms_ns(e.get('cuda_time_total',0.0)) for e in telemetry.get('events', []))\n",
    "print('[Summary] device:', summary.get('device'))\n",
    "print('[Summary] events:', len(telemetry.get('events', [])))\n",
    "print('[Summary] CPU total ms (inference):', round(total_cpu_ms, 3))\n",
    "print('[Summary] CUDA total ms (inference):', round(total_cuda_ms, 3))\n",
    "print('[Summary] training events:', len(train.get('events', [])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce33ab",
   "metadata": {},
   "source": [
    "## Visualize top events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "ev = telemetry.get('events', [])\n",
    "def top(evts, key, n=10):\n",
    "    return sorted(evts, key=lambda e: e.get(key, 0.0), reverse=True)[:n]\n",
    "# Prefer CPU on CPU-only runs\n",
    "top_cpu = top(ev, 'cpu_time_total')\n",
    "names = [e.get('name','') for e in top_cpu]\n",
    "vals = [e.get('cpu_time_total',0.0)/1e6 for e in top_cpu]\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.barh(names[::-1], vals[::-1])\n",
    "plt.xlabel('CPU time (ms)')\n",
    "plt.title('Top ops by CPU time (inference)')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900b26f",
   "metadata": {},
   "source": [
    "## Artifact paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab273d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "out = [\n",
    "    'telemetry.json',\n",
    "    'telemetry_train.json',\n",
    "    'agnitraai/context/layer_log_tinyllama.json',\n",
    "    'agnitraai/context/profile_result_tinyllama.json',\n",
    "]\n",
    "for p in out:\n",
    "    print('[Artifact]', p, 'exists:', Path(p).exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6351cc72",
   "metadata": {},
   "source": [
    "## Interactive CLI playground\n",
    "\n",
    "Run Agnitra commands without leaving the notebook.\n",
    "\n",
    "1. Pick a preset (or type your own command).\n",
    "2. Press **Run CLI** to execute it in this environment.\n",
    "3. Inspect stdout, stderr, and the exit code right below.\n",
    "\n",
    "Tip: Start with the profile preset to generate `telemetry.json`, which powers the IR views that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65872215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "except ImportError:\n",
    "    print(\"ipywidgets is required for the interactive CLI demo.\")\n",
    "    print(\"Install it via `pip install ipywidgets` and rerun this cell.\")\n",
    "else:\n",
    "    cwd = Path.cwd()\n",
    "    profile_target = cwd / \"tinyllama.pt\"\n",
    "    profile_arg = shlex.quote(str(profile_target)) if profile_target.exists() else \"tinyllama.pt\"\n",
    "\n",
    "    presets = {\n",
    "        \"Profile tinyllama (python -m cli.main)\": (\n",
    "            f\"python -m cli.main profile {profile_arg} --input-shape 1,16,64 \"\n",
    "            \"--output telemetry_interactive.json\"\n",
    "        ),\n",
    "        \"Optimize demo model\": \"python -m cli.optimize --model demo-model\",\n",
    "        \"Show agnitra help\": \"agnitra --help\",\n",
    "    }\n",
    "\n",
    "    preset_keys = list(presets.keys())\n",
    "    default_status = f\"<span style='color:#616161;'>Ready · cwd: {cwd}</span>\"\n",
    "\n",
    "    preset = widgets.Dropdown(\n",
    "        options=preset_keys,\n",
    "        description=\"Preset\",\n",
    "        layout=widgets.Layout(width=\"50%\"),\n",
    "    )\n",
    "    run_button = widgets.Button(description=\"Run CLI\", icon=\"play\", button_style=\"success\")\n",
    "    clear_button = widgets.Button(description=\"Clear\", icon=\"trash\", layout=widgets.Layout(width=\"100px\"))\n",
    "    status = widgets.HTML(value=default_status)\n",
    "    command = widgets.Textarea(\n",
    "        value=presets[preset_keys[0]],\n",
    "        description=\"Command\",\n",
    "        layout=widgets.Layout(width=\"100%\", height=\"80px\"),\n",
    "        continuous_update=False,\n",
    "    )\n",
    "    output = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "    def _apply_preset(change):\n",
    "        new_value = change.get(\"new\")\n",
    "        if new_value in presets:\n",
    "            command.value = presets[new_value]\n",
    "\n",
    "    def _render_status(message: str, color: str = \"#616161\") -> None:\n",
    "        status.value = f\"<span style='color:{color};'>{message}</span>\"\n",
    "\n",
    "    def _run_command(_):\n",
    "        text = command.value.strip()\n",
    "        if not text:\n",
    "            _render_status(\"Enter a command to run.\", color=\"#c62828\")\n",
    "            return\n",
    "        try:\n",
    "            args = shlex.split(text)\n",
    "        except ValueError as err:\n",
    "            _render_status(f\"Parse error: {err}\", color=\"#c62828\")\n",
    "            return\n",
    "\n",
    "        run_button.disabled = True\n",
    "        run_button.icon = \"hourglass-half\"\n",
    "        run_button.button_style = \"warning\"\n",
    "        _render_status(\"Running...\", color=\"#0277bd\")\n",
    "        output.clear_output()\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(args, text=True, capture_output=True, cwd=str(cwd))\n",
    "        except FileNotFoundError as err:\n",
    "            _render_status(str(err), color=\"#c62828\")\n",
    "        except Exception as exc:\n",
    "            _render_status(f\"Failed: {exc}\", color=\"#c62828\")\n",
    "        else:\n",
    "            with output:\n",
    "                print(\"$\", text)\n",
    "                if result.stdout:\n",
    "                    print(result.stdout)\n",
    "                if result.stderr:\n",
    "                    print(result.stderr, file=sys.stderr)\n",
    "                print(f\"[exit code] {result.returncode}\")\n",
    "                artifact_names = [\n",
    "                    \"telemetry_interactive.json\",\n",
    "                    \"telemetry.json\",\n",
    "                    \"telemetry_train.json\",\n",
    "                    \"telemetry_val.json\",\n",
    "                    \"graph_ir.json\",\n",
    "                ]\n",
    "                produced = []\n",
    "                for name in artifact_names:\n",
    "                    candidate = cwd / name\n",
    "                    if candidate.exists():\n",
    "                        try:\n",
    "                            produced.append(candidate.relative_to(cwd))\n",
    "                        except ValueError:\n",
    "                            produced.append(candidate)\n",
    "                if produced:\n",
    "                    print(\"Artifacts:\")\n",
    "                    for path in produced:\n",
    "                        print(f\"  • {path}\")\n",
    "            color = \"#2e7d32\" if result.returncode == 0 else \"#c62828\"\n",
    "            status_text = \"Finished\"\n",
    "            if result.returncode == 0:\n",
    "                status_text += \" · exit code 0\"\n",
    "            else:\n",
    "                status_text += f\" · exit code {result.returncode}\"\n",
    "            _render_status(status_text, color=color)\n",
    "        finally:\n",
    "            run_button.disabled = False\n",
    "            run_button.icon = \"play\"\n",
    "            run_button.button_style = \"success\"\n",
    "\n",
    "    def _clear_output(_):\n",
    "        output.clear_output()\n",
    "        status.value = default_status\n",
    "\n",
    "    preset.observe(_apply_preset, names=\"value\")\n",
    "    preset.value = preset_keys[0]\n",
    "    _apply_preset({\"new\": preset.value})\n",
    "    run_button.on_click(_run_command)\n",
    "    clear_button.on_click(_clear_output)\n",
    "\n",
    "    display(\n",
    "        widgets.VBox(\n",
    "            [\n",
    "                widgets.HBox([preset, run_button, clear_button]),\n",
    "                command,\n",
    "                status,\n",
    "                output,\n",
    "            ]\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e9a3a",
   "metadata": {},
   "source": [
    "## Inspect Graph IR\n",
    "\n",
    "Turn the TinyLlama demo into an FX-based intermediate representation enriched with telemetry from the CLI runs above. If telemetry is missing, the extractor still works (validation falls back gracefully)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ab67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from agnitra.core.ir.graph_extractor import extract_graph_ir\n",
    "from prepare_tinyllama import TinyLlama\n",
    "\n",
    "telemetry_candidates = [\n",
    "    Path(\"telemetry_interactive.json\"),\n",
    "    Path(\"telemetry.json\"),\n",
    "]\n",
    "telemetry_payload = None\n",
    "for candidate in telemetry_candidates:\n",
    "    if candidate.exists():\n",
    "        telemetry_payload = json.loads(candidate.read_text())\n",
    "        print(f\"Loaded telemetry from {candidate}.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"No telemetry file found; run the profiling CLI preset above to gather telemetry overlays.\")\n",
    "\n",
    "model = TinyLlama().eval()\n",
    "example_inputs = (torch.randn(1, 16, 64),)\n",
    "\n",
    "try:\n",
    "    graph_ir = extract_graph_ir(\n",
    "        model,\n",
    "        example_inputs=example_inputs,\n",
    "        telemetry=telemetry_payload,\n",
    "        validate=True,\n",
    "    )\n",
    "except ValueError as exc:\n",
    "    print(f\"Validation failed: {exc}\")\n",
    "    print(\"Retrying with validate=False so you can still inspect the graph.\")\n",
    "    graph_ir = extract_graph_ir(\n",
    "        model,\n",
    "        example_inputs=example_inputs,\n",
    "        telemetry=telemetry_payload,\n",
    "        validate=False,\n",
    "    )\n",
    "\n",
    "node_count = len(graph_ir)\n",
    "with_cuda = sum(1 for node in graph_ir if node.get(\"cuda_time_ms\") is not None)\n",
    "with_cpu = sum(1 for node in graph_ir if node.get(\"cpu_time_ms\") is not None)\n",
    "print(f\"Extracted {node_count} IR nodes.\")\n",
    "print(f\"  • {with_cuda} nodes carry CUDA timing data\")\n",
    "print(f\"  • {with_cpu} nodes carry CPU timing data\")\n",
    "\n",
    "ir_path = Path(\"graph_ir.json\")\n",
    "ir_path.write_text(json.dumps(graph_ir, indent=2))\n",
    "print(f\"Saved a snapshot to {ir_path.resolve()}\")\n",
    "\n",
    "graph_ir[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb82874",
   "metadata": {},
   "source": [
    "### Interactive IR explorer\n",
    "\n",
    "Filter, search, and visualise the IR nodes. Change the metric, narrow by FX node kind, or focus on specific telemetry sources to highlight hotspots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "if \"graph_ir\" not in globals():\n",
    "    raise RuntimeError(\"Run the IR extraction cell above first.\")\n",
    "\n",
    "if not graph_ir:\n",
    "    raise ValueError(\"Graph IR is empty; run the profiling flow and extraction again.\")\n",
    "\n",
    "df_ir = pd.DataFrame(graph_ir)\n",
    "\n",
    "if \"telemetry_sources\" not in df_ir:\n",
    "    df_ir[\"telemetry_sources\"] = [[] for _ in range(len(df_ir))]\n",
    "else:\n",
    "    df_ir[\"telemetry_sources\"] = df_ir[\"telemetry_sources\"].apply(\n",
    "        lambda items: items if isinstance(items, list) else []\n",
    "    )\n",
    "\n",
    "numeric_cols = [\n",
    "    \"cuda_time_ms\",\n",
    "    \"cpu_time_ms\",\n",
    "    \"memory_bytes\",\n",
    "]\n",
    "for col in numeric_cols:\n",
    "    if col in df_ir:\n",
    "        df_ir[col] = pd.to_numeric(df_ir[col], errors=\"coerce\")\n",
    "\n",
    "summary_lines = [\n",
    "    f\"Total nodes: {len(df_ir)}\",\n",
    "    f\"call_module nodes: {int((df_ir['kind'] == 'call_module').sum())}\",\n",
    "    f\"Nodes with telemetry: {int(df_ir['telemetry_sources'].apply(bool).sum())}\",\n",
    "]\n",
    "\n",
    "summary_md = \"**Quick stats**\\n\\n\" + \"\\n\".join(f\"- {line}\" for line in summary_lines)\n",
    "display(Markdown(summary_md))\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    print(\"ipywidgets and matplotlib are required for the interactive view. Install via `pip install ipywidgets matplotlib`.\")\n",
    "else:\n",
    "    try:\n",
    "        import plotly.express as px  # type: ignore\n",
    "    except ImportError:  # Plotly is optional\n",
    "        px = None\n",
    "        print(\"Plotly not installed; falling back to static Matplotlib charts. Install via `pip install plotly` for interactivity.\")\n",
    "\n",
    "    metric_options = [\n",
    "        (\"CUDA time (ms)\", \"cuda_time_ms\"),\n",
    "        (\"CPU time (ms)\", \"cpu_time_ms\"),\n",
    "        (\"Memory bytes\", \"memory_bytes\"),\n",
    "    ]\n",
    "    metric_lookup = {value: label for label, value in metric_options}\n",
    "    metric_dropdown = widgets.Dropdown(options=metric_options, value=\"cuda_time_ms\", description=\"Metric\")\n",
    "\n",
    "    max_top = max(1, min(30, len(df_ir))) if len(df_ir) else 10\n",
    "    min_top = 1 if max_top < 3 else 3\n",
    "    default_top = min(10, max_top)\n",
    "    top_n_slider = widgets.IntSlider(\n",
    "        value=max(default_top, min_top),\n",
    "        min=min_top,\n",
    "        max=max_top,\n",
    "        step=1,\n",
    "        description=\"Top N\",\n",
    "    )\n",
    "\n",
    "    kinds = sorted(k for k in df_ir[\"kind\"].dropna().unique())\n",
    "    telemetry_tags = sorted({tag for tags in df_ir[\"telemetry_sources\"] for tag in (tags or [])})\n",
    "\n",
    "    kind_selector = widgets.SelectMultiple(\n",
    "        options=kinds,\n",
    "        description=\"Kinds\",\n",
    "        layout=widgets.Layout(width=\"200px\", height=\"180px\"),\n",
    "    )\n",
    "    telemetry_selector = widgets.SelectMultiple(\n",
    "        options=telemetry_tags,\n",
    "        description=\"Telemetry\",\n",
    "        layout=widgets.Layout(width=\"200px\", height=\"180px\"),\n",
    "    )\n",
    "    name_filter = widgets.Text(placeholder=\"Substring filter (name/op)\", description=\"Search\")\n",
    "    output_table = widgets.Output()\n",
    "\n",
    "    def _filter_frame():\n",
    "        frame = df_ir.copy()\n",
    "        if kind_selector.value:\n",
    "            frame = frame[frame[\"kind\"].isin(kind_selector.value)]\n",
    "        if telemetry_selector.value:\n",
    "            selected = set(telemetry_selector.value)\n",
    "            frame = frame[\n",
    "                frame[\"telemetry_sources\"].apply(lambda items: bool(selected.intersection(items)))\n",
    "            ]\n",
    "        text = name_filter.value.strip()\n",
    "        if text:\n",
    "            frame = frame[\n",
    "                frame[\"name\"].str.contains(text, case=False, na=False)\n",
    "                | frame[\"op\"].str.contains(text, case=False, na=False)\n",
    "            ]\n",
    "        return frame\n",
    "\n",
    "    def _render(_=None):\n",
    "        frame = _filter_frame()\n",
    "        metric = metric_dropdown.value\n",
    "        output_table.clear_output()\n",
    "        with output_table:\n",
    "            if metric not in frame or frame.empty:\n",
    "                print(\"No nodes match the current filter.\")\n",
    "                return\n",
    "            subset = frame[[\"name\", \"op\", metric, \"kind\", \"telemetry_sources\"]].dropna(subset=[metric])\n",
    "            subset = subset.sort_values(metric, ascending=False).head(top_n_slider.value)\n",
    "            if subset.empty:\n",
    "                print(\"No numeric data available for the chosen metric.\")\n",
    "                return\n",
    "            display(subset.reset_index(drop=True))\n",
    "            if px is not None:\n",
    "                fig = px.bar(\n",
    "                    subset,\n",
    "                    x=metric,\n",
    "                    y=\"name\",\n",
    "                    orientation=\"h\",\n",
    "                    color=\"kind\",\n",
    "                    hover_data=[\"op\", \"telemetry_sources\"],\n",
    "                    title=\"Top IR nodes\",\n",
    "                )\n",
    "                fig.update_layout(height=420, margin=dict(l=0, r=0, t=60, b=0))\n",
    "                fig.show()\n",
    "            else:\n",
    "                fig, ax = plt.subplots(figsize=(10, 4))\n",
    "                ax.barh(subset[\"name\"][::-1], subset[metric][::-1], color=\"#1976d2\")\n",
    "                ax.set_xlabel(metric_lookup.get(metric, metric))\n",
    "                ax.set_ylabel(\"Node\")\n",
    "                ax.set_title(\"Top IR nodes\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    metric_dropdown.observe(_render, names=\"value\")\n",
    "    kind_selector.observe(_render, names=\"value\")\n",
    "    telemetry_selector.observe(_render, names=\"value\")\n",
    "    name_filter.observe(_render, names=\"value\")\n",
    "    top_n_slider.observe(_render, names=\"value\")\n",
    "\n",
    "    controls = widgets.HBox(\n",
    "        [\n",
    "            widgets.VBox([metric_dropdown, top_n_slider, name_filter]),\n",
    "            widgets.VBox([kind_selector, telemetry_selector]),\n",
    "        ]\n",
    "    )\n",
    "    display(widgets.VBox([controls, output_table]))\n",
    "    _render()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
